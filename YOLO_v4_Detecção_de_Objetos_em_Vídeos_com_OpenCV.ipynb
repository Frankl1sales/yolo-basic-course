{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "35fTeGnheczl"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frankl1sales/yolo-basic-course/blob/main/YOLO_v4_Detec%C3%A7%C3%A3o_de_Objetos_em_V%C3%ADdeos_com_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c0p0eWP672d"
      },
      "source": [
        "# Detectando objetos em vídeos com YOLOv4 e OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdqDEz3C7Gsw"
      },
      "source": [
        "## Etapa 1 - Importando as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Sl5Vhf4q0e"
      },
      "source": [
        "import cv2\n",
        "print(cv2.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRBF8b5o0Ae7"
      },
      "source": [
        "!pip install opencv-python==4.9.0.80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONee8yfzbFJp"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile\n",
        "print(cv2.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05vKSzso7Kvw"
      },
      "source": [
        "## Etapa 2 - Conectando com o Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlXvULPEa-bZ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxlRGgZV7d_r"
      },
      "source": [
        "## Etapa 3 - Carregando os arquivos do modelo treinado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TmtEny4sdyH"
      },
      "source": [
        "path =  '/content/gdrive/MyDrive/home/2. PESQUISAS/4. Org. Cursos/Udemy/YOLO/modelo_YOLOv4.zip'\n",
        "zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n",
        "zip_object.extractall(\"./\")\n",
        "zip_object.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkGd4ASWbLk5"
      },
      "source": [
        "labels_path = os.path.sep.join(['/content/cfg', \"coco.names\"])\n",
        "LABELS = open(labels_path).read().strip().split(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAP1oeyfGXdi"
      },
      "source": [
        "weights_path = os.path.sep.join(['/content/', \"yolov4.weights\"])\n",
        "config_path = os.path.sep.join(['/content/cfg', \"yolov4.cfg\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voiXcNqEGZkd"
      },
      "source": [
        "net = cv2.dnn.readNet(config_path, weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3zdFwT881pS"
      },
      "source": [
        "## Etapa 4 - Definindo mais configurações para a detecção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dul5BbIkKaqj"
      },
      "source": [
        "np.random.seed(42)\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRrXAEWHs27Y"
      },
      "source": [
        "ln = net.getLayerNames()\n",
        "print(\"Todas as camadas (layers):\")\n",
        "print(ln)\n",
        "print(\"Total: \"+ str(len(ln)))\n",
        "print(\"Camadas de saída: \")\n",
        "print(net.getUnconnectedOutLayers())\n",
        "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "print(ln)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqc359lDATAh"
      },
      "source": [
        "## Etapa 5 - Criando as funções para detecção e processamento do video\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2w30TyWCcZu"
      },
      "source": [
        "### Função para exibir imagens no Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg5ZQD6soINW"
      },
      "source": [
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(16, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vat9IbYuzBE_"
      },
      "source": [
        "### Construindo o blob da imagem\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ7J84o70ao8"
      },
      "source": [
        "def blob_imagem(net, imagem, mostrar_texto=True):\n",
        "  inicio = time.time()\n",
        "  blob = cv2.dnn.blobFromImage(imagem, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "  net.setInput(blob)\n",
        "  layerOutputs = net.forward(ln)\n",
        "  termino = time.time()\n",
        "  if mostrar_texto:\n",
        "    print(\"YOLO levou {:.2f} segundos\".format(termino - inicio))\n",
        "  return net, imagem, layerOutputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wkis49_-VxD"
      },
      "source": [
        "### Realizando a detecção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MOUOfivV-c5"
      },
      "source": [
        "def deteccoes(detection, _threshold, caixas, confiancas, IDclasses):\n",
        "  scores = detection[5:]\n",
        "  classeID = np.argmax(scores)\n",
        "  confianca = scores[classeID]\n",
        "\n",
        "  if confianca > _threshold:\n",
        "      caixa = detection[0:4] * np.array([W, H, W, H])\n",
        "      (centerX, centerY, width, height) = caixa.astype(\"int\")\n",
        "\n",
        "      x = int(centerX - (width / 2))\n",
        "      y = int(centerY - (height / 2))\n",
        "\n",
        "      caixas.append([x, y, int(width), int(height)])\n",
        "      confiancas.append(float(confianca))\n",
        "      IDclasses.append(classeID)\n",
        "\n",
        "  return caixas, confiancas, IDclasses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOwTXTg--tYj"
      },
      "source": [
        "### Mostrando o resultado da detecção no video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ETrpQKQ4pBa"
      },
      "source": [
        "def funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=True):\n",
        "  (x, y) = (caixas[i][0], caixas[i][1])\n",
        "  (w, h) = (caixas[i][2], caixas[i][3])\n",
        "\n",
        "  cor = [int(c) for c in COLORS[IDclasses[i]]]\n",
        "  cv2.rectangle(imagem, (x, y), (x + w, y + h), cor, 2)\n",
        "  texto = \"{}: {:.4f}\".format(LABELS[IDclasses[i]], confiancas[i])\n",
        "  if mostrar_texto:\n",
        "    print(\"> \" + texto)\n",
        "    print(x,y,w,h)\n",
        "  cv2.putText(imagem, texto, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, cor, 2)\n",
        "\n",
        "  return imagem,x,y,w,h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzv-6h7477z5"
      },
      "source": [
        "## Etapa 6 - Carregando o vídeo onde será feita a detecção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmDcELnJOBTq"
      },
      "source": [
        "### 6.1 - De uma url"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlrbm3mMOGhS"
      },
      "source": [
        "!wget https://github.com/gabevr/yolo/raw/master/videos/video_pessoas01.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQTcJu03OY6q"
      },
      "source": [
        "### 6.2 - Do Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gdrive/MyDrive/home/2.\\ PESQUISAS/4.\\ Org.\\ Cursos/Udemy/YOLO/videos/video_pessoas01.mp4 ./"
      ],
      "metadata": {
        "id": "DgJ-bjoWPMrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXCgPeVVOby6"
      },
      "source": [
        "### Lendo o arquivo de vídeo com o OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp6UaJE5R7T0"
      },
      "source": [
        "arquivo_video = 'video_pessoas01.mp4'\n",
        "cap = cv2.VideoCapture(arquivo_video)\n",
        "conectado, video = cap.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVcmO4OmSS-h"
      },
      "source": [
        "conectado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg6WM0noSaPt"
      },
      "source": [
        "video.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cn2tQqfSgaZ"
      },
      "source": [
        "video_largura = video.shape[1]\n",
        "video_altura = video.shape[0]\n",
        "video_largura, video_altura"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKqI-fx99utO"
      },
      "source": [
        "## Etapa 7 - Redimensionamento do tamanho do video (opcional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Welhd3A5aM"
      },
      "source": [
        "def redimensionar(largura, altura, largura_maxima = 600):\n",
        "  if (largura > largura_maxima):\n",
        "    proporcao = largura / altura\n",
        "    video_largura = largura_maxima\n",
        "    video_altura = int(video_largura / proporcao)\n",
        "  else:\n",
        "    video_largura = largura\n",
        "    video_altura = altura\n",
        "\n",
        "  return video_largura, video_altura"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unUjT4cZMrAa"
      },
      "source": [
        "video_largura, video_altura = redimensionar(video.shape[1], video.shape[0])\n",
        "print(video_largura,video_altura)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmTdl-SXByYW"
      },
      "source": [
        "## Etapa 8 - Definindo as configurações do vídeo\n",
        "\n",
        "- Mais exemplos de outras configurações com o fourcc que é possível usar: https://www.programcreek.com/python/example/89348/cv2.VideoWriter_fourcc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX__kKpYTE5Q"
      },
      "source": [
        "nome_arquivo = 'resultado.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') # MP4V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0moxehGETvyr"
      },
      "source": [
        "fps = 24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmXS8Y7VT0rI"
      },
      "source": [
        "saida_video = cv2.VideoWriter(nome_arquivo, fourcc, fps, (video_largura, video_altura))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQzpImT4-H1F"
      },
      "source": [
        "## Etapa 9 - Definindo as variáveis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AUrERe_UQgs"
      },
      "source": [
        "threshold = 0.5\n",
        "threshold_NMS = 0.3\n",
        "fonte_pequena, fonte_media = 0.4, 0.6\n",
        "fonte = cv2.FONT_HERSHEY_SIMPLEX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMJ8RhqsUliW"
      },
      "source": [
        "amostras_exibir = 20\n",
        "amostra_atual = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifu1dDTKP-mX"
      },
      "source": [
        "## Etapa 10 - Processamento do vídeo e exibição do resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yak18CwkU1_Y"
      },
      "source": [
        "while (cv2.waitKey(1) < 0):\n",
        "  conectado, frame = cap.read()\n",
        "  if not conectado:\n",
        "    break\n",
        "  t = time.time()\n",
        "  frame = cv2.resize(frame, (video_largura, video_altura))\n",
        "  try:\n",
        "    (H, W) = frame.shape[:2]\n",
        "  except:\n",
        "    print('Erro')\n",
        "    continue\n",
        "\n",
        "  imagem_cp = frame.copy()\n",
        "  net, frame, layerOutputs = blob_imagem(net, frame)\n",
        "  caixas = []\n",
        "  confiancas = []\n",
        "  IDclasses = []\n",
        "\n",
        "  for output in layerOutputs:\n",
        "    for detection in output:\n",
        "      caixas, confiancas, IDclasses = deteccoes(detection, threshold, caixas, confiancas, IDclasses)\n",
        "\n",
        "  objs = cv2.dnn.NMSBoxes(caixas, confiancas, threshold, threshold_NMS)\n",
        "\n",
        "  if len(objs) > 0:\n",
        "    for i in objs.flatten():\n",
        "      frame, x, y, w, h = funcoes_imagem(frame, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=False)\n",
        "      objeto = imagem_cp[y:y + h, x:x + w]\n",
        "\n",
        "  cv2.putText(frame, \" frame processado em {:.2f} segundos\".format(time.time() - t),\n",
        "              (20, video_altura-20), fonte, fonte_pequena, (250, 250, 250), 0, lineType=cv2.LINE_AA)\n",
        "\n",
        "  if amostra_atual <= amostras_exibir:\n",
        "    cv2_imshow(frame)\n",
        "    amostra_atual += 1\n",
        "\n",
        "  saida_video.write(frame)\n",
        "\n",
        "print('Terminou')\n",
        "saida_video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fdV8vq6aEO5"
      },
      "source": [
        "\\!du -h resultado.avi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKuk7P8aaF4B"
      },
      "source": [
        "!cp ./resultado.avi /content/gdrive/MyDrive/home/2.\\ PESQUISAS/4.\\ Org.\\ Cursos/Udemy/YOLO/videos/resultado03.avi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alteração do formato do vídeo para codec h.264"
      ],
      "metadata": {
        "id": "xa0JWEKcWcnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg\n"
      ],
      "metadata": {
        "id": "4j658Y4pWyy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i \"/content/gdrive/MyDrive/home/2. PESQUISAS/4. Org. Cursos/Udemy/YOLO/videos/resultado03.avi\" \\\n",
        "-c:v libx264 -c:a aac -strict experimental \\\n",
        "\"/content/gdrive/MyDrive/home/2. PESQUISAS/4. Org. Cursos/Udemy/YOLO/videos/resultado3_whatsapp3.mp4\""
      ],
      "metadata": {
        "id": "hvKS8YX5WqJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i \"/content/gdrive/MyDrive/home/2. PESQUISAS/4. Org. Cursos/Udemy/YOLO/videos/resultado03.avi\" \\\n",
        "-c:v libx264 -preset fast -crf 23 -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -r 30 -c:a aac -b:a 128k -strict experimental \\\n",
        "\"/content/gdrive/MyDrive/home/2. PESQUISAS/4. Org. Cursos/Udemy/YOLO/videos/resultado3_whatsapp3.mp4\"\n"
      ],
      "metadata": {
        "id": "V4dOV-9NZkG-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}